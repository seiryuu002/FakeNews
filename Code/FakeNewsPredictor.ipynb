{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocess_kgptalkie as ps\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('F:\\\\Lecture notes\\\\Sem-5\\\\MP-III\\\\Dataset\\\\Fake.csv')\n",
    "real = pd.read_csv('F:\\\\Lecture notes\\\\Sem-5\\\\MP-III\\\\Dataset\\\\True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_publishers = []\n",
    "for index, row in enumerate(real.text.values):\n",
    "    try:\n",
    "        record = row.split('-', maxsplit = 1)\n",
    "        record[1]\n",
    "        assert(len(record[0])<120)\n",
    "    except:\n",
    "        unknown_publishers.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real.drop(8970, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher = []\n",
    "tmp_text = []\n",
    "\n",
    "for index, row in enumerate(real.text.values):\n",
    "    if index in unknown_publishers:\n",
    "        tmp_text.append(row)\n",
    "        publisher.append('Unknown')\n",
    "\n",
    "    else:\n",
    "        record = row.split('-', maxsplit = 1)\n",
    "        publisher.append(record[0].strip())\n",
    "        tmp_text.append(record[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['publisher'] = publisher\n",
    "real['text'] = tmp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fake_index = [ index for index,text in enumerate (fake.text.tolist()) if str(text).strip() == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['text'] = real['title'] + \" \" + real['text']\n",
    "fake['text'] = fake['title'] + \" \" + fake['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['text'] = real['text'].apply(lambda x: str(x).lower())\n",
    "fake['text'] = fake['text'].apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['class'] = 1\n",
    "fake['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real[['text', 'class']]\n",
    "fake = fake[['text', 'class']]\n",
    "data = real.append(fake, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: ps.remove_special_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['class'].values\n",
    "X = [d.split() for d in data['text'].tolist()]\n",
    "DIM = 100\n",
    "w2v_model = gensim.models.Word2Vec(sentences=X, window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 1000\n",
    "X = pad_sequences(X, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matrix(model):\n",
    "    weight_matrix = np.zeros((vocab_size, 100))\n",
    "    \n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model.wv[word]\n",
    "    \n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = get_weight_matrix(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, output_dim = 100, weights = [embedding_vectors], input_length = max_len, trainable=False))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "737/737 [==============================] - 127s 145ms/step - loss: 0.2076 - acc: 0.9176 - val_loss: 0.1367 - val_acc: 0.9496\n",
      "Epoch 2/6\n",
      "737/737 [==============================] - 149s 203ms/step - loss: 0.0831 - acc: 0.9710 - val_loss: 0.0629 - val_acc: 0.9788\n",
      "Epoch 3/6\n",
      "737/737 [==============================] - 188s 256ms/step - loss: 0.0356 - acc: 0.9889 - val_loss: 0.0448 - val_acc: 0.9859\n",
      "Epoch 4/6\n",
      "737/737 [==============================] - 188s 255ms/step - loss: 0.0368 - acc: 0.9880 - val_loss: 0.0260 - val_acc: 0.9924\n",
      "Epoch 5/6\n",
      "737/737 [==============================] - 212s 287ms/step - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0259 - val_acc: 0.9922\n",
      "Epoch 6/6\n",
      "737/737 [==============================] - 193s 262ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.0238 - val_acc: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e8e08e14f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split = 0.3, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_test) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input(\"Enter News to check for Real or Fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer.texts_to_sequences(x)\n",
    "x = pad_sequences(x, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = (model.predict(x)>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if news == 1:\n",
    "    print(\"It's a Real News\")\n",
    "else:\n",
    "    print(\"It's a Fake News\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
